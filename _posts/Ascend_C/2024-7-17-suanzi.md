---
title: 华为Ascend C算子开发笔记
---
# 算子组成
## 1. Host
是CPU及其可访问的系统内存环境。在这个环境中运行的代码负责管理应用程序的主要流程，包括准备数据、调度任务、以及处理I/O等。

## 2. Kernel
是在GPU或其他专用加速器上执行的代码。这些代码通常被设计为小的、高度并行的计算任务，称为"kernel"。Kernel由host端发起调用，并在加速器硬件上异步执行。

# Acsend C 算子开发流程
算子开发包括多个侧,包括Host,Kernel,测试.每个侧的内部相对独立,仅通过部分参数进行信息传递,可以进行并行开发.

具体的开发方式相对方便,仅需设置配置文件,执行特定命令后即可自动创建开发模板.
```json
[
    {
        "op": "AddCustom",
        "input_desc": [
            {
                "name": "x",
                "param_type": "required",
                "format": [
                    "ND"
                ],
                "type": [
                    "fp16"
                ]
            },
            {
                "name": "y",
                "param_type": "required",
                "format": [
                    "ND"
                ],
                "type": [
                    "fp16"
                ]
            }
        ],
        "output_desc": [
            {
                "name": "z",
                "param_type": "required",
                "format": [
                    "ND"
                ],
                "type": [
                    "fp16"
                ]
            }
        ]
    }
]
```
命令如下
```
${INSTALL_DIR}/python/site-packages/bin/msopgen gen -i $HOME/sample/add_custom.json -c ai_core-<soc_version> -lan cpp -out   $HOME/sample/AddCustom
```
后续就可以开始对Host等代码的编写了


# 优化算子性能的方式
1. 减少api的使用率和辅助空间的使用
每次调用api都会造成运行开销,在设计算子时要尽可能在api使用率尽可能少的情况下实现功能.
比较sinh的两种实现
```
A=e^x
x=-x
B=e^-x
y=(A-B)/2
```

```
A=e^x
B=1/A
y=(A-B)*0.5
```
显然第二种使用了更少的api,也使用了更快的api实现相同功能,因为乘法单元比除法单元更快

2. 代码模块化
将矩阵/向量运算的代码与标量运算的代码区分开来,使得CPU/NPU能够发挥优势性能.

例如在Host端可以做一些数据处理:
```cpp
constexpr int32_t TOTAL_LENGTH = 8 * 2048;                            // total length of data
constexpr int32_t USE_CORE_NUM = 8;                                   // num of core used
constexpr int32_t BLOCK_LENGTH = TOTAL_LENGTH / USE_CORE_NUM;         // length computed of each core
constexpr int32_t TILE_NUM = 8;                                       // split data into 8 tiles for each core
constexpr int32_t BUFFER_NUM = 2;                                     // tensor num for each queue
constexpr int32_t TILE_LENGTH = BLOCK_LENGTH / TILE_NUM / BUFFER_NUM
```
由于这些处理需要用到标量乘法除法,让cpu去处理会更加高效,反之,如果把部分运算放进Kernel部分,不仅会增加每次循环额外的计算,也会导致运算资源分配不均,算子效率降低.

华为的AI Core中包含计算单元、存储单元、搬运单元等核心组件.优化性能归根结底就是要让这几个单元能够异步运行.

1. 计算单元
计算单元包含多个核,核之间可以并行.通过切分输入数据可以将互不影响的工作分配到多个核,提高运算效率.

2. 存储单元
存储单元主要是缓存相关的问题.针对不同的切分策略,要将总缓存(大小固定)分割成不同的区域,每个区域刚好能存下一次计算所需要的数据量

3. 搬运单元
搬运单元负责将CPU中准备的数据传递给NPU,再将NPU的运算结果传递给CPU.利用队列来实现工作流,输入命名为InQueue,输出命名为OutQueue.

前一个处理器处理完的数据将被传入到流中等待,直到后一个处理器完成它的任务.为了节省空间,同时避免阻塞,给每个Queue只分配固定大小的空间,如
```cpp
pipe.InitBuffer(inQueueX, BUFFER_NUM, TILE_LENGTH * sizeof(half));
```
使其最多能容纳`BUFFER_NUM`个数据单元


# 需要注意的事项:
1. 申请内存要先在tiling文件中添加需要申请的变量
```cpp
namespace optiling {
BEGIN_TILING_DATA_DEF(TilingData)
  // AddCustom算子使用了2个tiling参数：totalLength与tileNum
  TILING_DATA_FIELD_DEF(uint32_t, totalLength);     // 总计算数据量
  TILING_DATA_FIELD_DEF(uint32_t, tileNum);         // 每个核上总计算数据分块个数
END_TILING_DATA_DEF;
}
```

2. 设计完算子后需要先进行build后再进行测试
